{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My helper functions...\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys\n",
    "#os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "from numpy import unique\n",
    "from numpy import random \n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from math import ceil\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from random import shuffle\n",
    "import io\n",
    "import zlib\n",
    "from scipy.ndimage import imread\n",
    "import scipy\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from IPython.core.display import display, HTML\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "import smtplib\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshlab(x, thresh=None):\n",
    "    out = 0\n",
    "    try:\n",
    "        if float(x)*thresh[1] >= thresh[0]*thresh[1]:\n",
    "            out = 1\n",
    "    except:\n",
    "        pass\n",
    "    return out\n",
    "\n",
    "def isNaN(num):\n",
    "    return num != num\n",
    "\n",
    "def balanced_sample_maker(X, y, random_seed=None):\n",
    "    \"\"\" return a balanced data set by oversampling minority class \n",
    "        current version is developed on assumption that the positive\n",
    "        class is the minority.\n",
    "\n",
    "    Parameters:\n",
    "    ===========\n",
    "    X: {numpy.ndarrray}\n",
    "    y: {numpy.ndarray}\n",
    "    \"\"\"\n",
    "    uniq_levels = unique(y)\n",
    "    uniq_counts = {level: sum(y == level) for level in uniq_levels}\n",
    "\n",
    "    if not random_seed is None:\n",
    "        random.seed(random_seed)\n",
    "\n",
    "    # find observation index of each class levels\n",
    "    groupby_levels = {}\n",
    "    for ii, level in enumerate(uniq_levels):\n",
    "        obs_idx = [idx for idx, val in enumerate(y) if val == level]\n",
    "        groupby_levels[level] = obs_idx\n",
    "\n",
    "    # oversampling on observations of positive label\n",
    "    sample_size = uniq_counts[0]\n",
    "    over_sample_idx = random.choice(groupby_levels[1], size=sample_size, replace=True).tolist()\n",
    "    balanced_copy_idx = groupby_levels[0] + over_sample_idx\n",
    "    random.shuffle(balanced_copy_idx)\n",
    "\n",
    "    return [X[i] for i in balanced_copy_idx], [y[i] for i in balanced_copy_idx]\n",
    "\n",
    "def getlabelsfromicd(ICDs, diagnosis_df):\n",
    "    MRN = []\n",
    "    for i in range(len(diagnosis_df)):\n",
    "        intersection = list(set(ICDs) & set(diagnosis_df.iloc[i]))\n",
    "        if len(intersection) > 0:\n",
    "            MRN.append(diagnosis_df['MRN'].iloc[i])\n",
    "        else:\n",
    "            pass\n",
    "    return MRN\n",
    "\n",
    "def comorbiditiesfromicd(ICDs, diagnosis_df):\n",
    "    label = []\n",
    "    for list_ in ICDs:\n",
    "        intersection = list(set(list_) & set(diagnosis_df))\n",
    "        if len(intersection) > 0:\n",
    "            label.append(1)\n",
    "        else:\n",
    "            label.append(0)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('traintest_processed.pickle', 'rb') as handle:\n",
    "    train_X, train_X_comorbidities, train_Y = pickle.load(handle)\n",
    "\n",
    "with open('holdout_processed.pickle', 'rb') as handle:\n",
    "    test_X, test_X_comorbidities, test_Y = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_train_c(train_X,train_X_comorbidities):\n",
    "    train_X_merged = []\n",
    "    for i in range(train_X.shape[0]):\n",
    "        train_X_merged.append(np.insert(train_X[i].flatten(),0,train_X_comorbidities[i]))\n",
    "    return np.array(train_X_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_merged = merge_train_c(train_X,train_X_comorbidities)\n",
    "test_X_merged = merge_train_c(test_X, test_X_comorbidities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=5, random_state=0, n_jobs = multiprocessing.cpu_count()-1)\n",
    "clf.fit(train_X_merged, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "import pickle\n",
    "with open('/home/jkim/varun/models/04_27_2020_rfmodel.pickle', 'wb') as handle:\n",
    "    pickle.dump(clf, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "import pickle\n",
    "with open('/home/jkim/varun/models/04_27_2020_rfmodel.pickle', 'rb') as handle:\n",
    "    clf = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_flat = list(test_Y)\n",
    "Y_pred_flat = list(clf.predict_proba(test_X_merged)[:,1:])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "%matplotlib inline\n",
    "\n",
    "fpr, tpr, _ = roc_curve(Y_flat, Y_pred_flat)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='NLP')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "AUC = roc_auc_score(Y_flat, Y_pred_flat)\n",
    "\n",
    "print('AUROC score: {}'.format(AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.utils.fixes import signature\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "average_precision = average_precision_score(Y_flat, Y_pred_flat)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(Y_flat, Y_pred_flat)\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_optimal_thresh(fpr, tpr, thresholds):\n",
    "    i = np.arange(len(tpr))\n",
    "    roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholds, index = i)})\n",
    "    thresh = roc.ix[(roc.tf-0).abs().argsort()[:1]]['thresholds'].iloc[0]\n",
    "    \n",
    "    return thresh\n",
    "\n",
    "pred = Y_pred_flat\n",
    "tru = Y_flat\n",
    "fpr, tpr, _ = roc_curve(tru, pred)\n",
    "optimal_threshold = compute_optimal_thresh(fpr, tpr, _)\n",
    "print(optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(Y_flat, np.where(np.array(Y_pred_flat)>=optimal_threshold,1,0))\n",
    "\n",
    "print('Accuracy: %{}'.format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_flat, np.where(np.array(Y_pred_flat)>optimal_threshold,1,0), target_names=['alive','died']))\n",
    "\n",
    "# Note that in binary classification, recall of the positive class is also known as “sensitivity”;\n",
    "# recall of the negative class is “specificity”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "maxlen = 50\n",
    "all_vars = ['hrs', 'PAO2', 'PACO2', 'HCO3', 'PH_x', 'Oxygen saturation','C REACTIVE PROTEIN', 'Creatinine', 'D-DIMER', 'Platelets', 'WBC_x', 'CAC - TEMPERATURE', 'CAC - PULSE', 'CAC - RESPIRATIONS', 'systolic', 'diastolic']\n",
    "\n",
    "tree_labels = [['copd', 'dm', 'dmwc', 'rd', 'ld', 'htn', 'htwc']]\n",
    "for i in range(maxlen):\n",
    "    tree_labels.append([x+'_t'+str(i) for x in all_vars])\n",
    "tree_labels = [item for sublist in tree_labels for item in sublist]\n",
    "print('Number of Trees: {}'.format(len(clf.estimators_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(clf.estimators_[0],\n",
    "                feature_names=tree_labels,\n",
    "                class_names = ['negative','positive'],\n",
    "                filled=True,\n",
    "                rounded=True,\n",
    "               precision=2,\n",
    "               proportion = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('dot -Tpng tree.dot -o tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='tree.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "with open('holdout_ptdata.pickle', 'rb') as handle:\n",
    "    pt_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ = list(pt_data.keys())[1]\n",
    "\n",
    "\n",
    "def format_preds(id_ = None, pt_data = None, clf = None):\n",
    "    X, C, Y = pt_data[id_]\n",
    "\n",
    "    X_merged = merge_train_c(X, C)\n",
    "    preds = [x[0] for x in clf.predict_proba(X_merged)[:,1:]]\n",
    "    label = list(Y)\n",
    "\n",
    "    flag = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        if flag == 0:\n",
    "            temp = pd.DataFrame(X[i]).drop_duplicates().reset_index(drop=True)\n",
    "            temp.columns = all_vars\n",
    "            temp['pred'] = preds[i]\n",
    "            temp['label'] = label[i]\n",
    "\n",
    "            df = temp\n",
    "            flag+=1\n",
    "        elif flag != 0:\n",
    "            temp = pd.DataFrame(X[i]).drop_duplicates().reset_index(drop=True)\n",
    "            temp.columns = all_vars\n",
    "            temp['pred'] = preds[i]\n",
    "            temp['label'] = label[i]\n",
    "\n",
    "            df.append(temp).reset_index(drop=True).drop_duplicates(subset=['hrs'], keep = 'last')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "pt_preds_df = defaultdict()\n",
    "\n",
    "for id_ in list(set(pt_data.keys())):\n",
    "    try:\n",
    "        df = format_preds(id_ = id_, pt_data = pt_data, clf = clf)\n",
    "        pt_preds_df[id_] = df\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
